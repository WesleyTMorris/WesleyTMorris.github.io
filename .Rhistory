} catch (error) {
console.error("Error clicking More Jobs button or button not found:", error);
break;
}
}
// Step 4: Fetch all job listing elements
let jobElements = await page.$$(jobSelector);
const totalJobs = jobElements.length; // Get the total number of jobs
console.log(`Found ${totalJobs} job listings.`);
// Step 5: Iterate through job listings
for (let i = 0; i < totalJobs; i++) {
try {
console.log(`Processing job listing ${i + 1} of ${totalJobs}...`); // Updated log
// Ensure fresh reference to the current element without re-fetching all elements
const jobElement = jobElements[i];
if (jobElement) {
await jobElement.click();
// Wait for job details to load completely (can include specific child elements)
await page.waitForSelector("#ApplicationDeadline-value", { timeout: 10000 }); // Wait for the job details container
// Fetch the HTML content inside #jobDetails-desktop
const jobContent = await page.evaluate(() => {
const jobDetails = document.querySelector("#jobDetails-desktop");
return jobDetails ? jobDetails.innerHTML : "";
});
// Define the file name
const fileName = path.join(saveFolder, `job_description_${i + 1}.html`);
// Write the content to an HTML file
fs.writeFileSync(fileName, jobContent);
console.log(`Saved full job content for job ${i + 1} of ${totalJobs} to ${fileName}`);
await page.waitForTimeout(300); // Slightly reduced wait
} else {
console.log(`Job element ${i + 1} of ${totalJobs} does not exist. Skipping.`);
}
} catch (error) {
console.error(`Error processing job ${i + 1} of ${totalJobs}:`, error);
}
}
console.log("Finished processing all job listings.");
await browser.close();
})();
', url, job_desc_folder)
# Specify the file path where you want to save the JavaScript code
js_file_path <- "/Users/wesleymorris/my-puppeteer-scraper/scraper_Puppeteer.js"
# Write the JavaScript code to the file
writeLines(js_code, con = js_file_path)
# Confirm that the file has been created
if (file.exists(js_file_path)) {
cat("JavaScript file successfully created at:", js_file_path, "\n")
} else {
stop("Failed to create JavaScript file.")
}
# Run the JavaScript code using Puppeteer
system(sprintf("cd /Users/wesleymorris/my-puppeteer-scraper && node %s", shQuote(js_file_path)))
# Set up the current date and directory structure
current_date <- format(Sys.Date(), "%Y%m%d")
new_folder_path <- file.path("/Users/wesleymorris/Desktop/EPP Geography/data/", current_date)
dir.create(new_folder_path, recursive = TRUE)  # Create parent directories if needed
base_directory <- paste(new_folder_path, "html/", sep = "/")
dir.create(base_directory)
# Create the Job_Descriptions folder
job_desc_folder <- file.path(new_folder_path, "Job_Descriptions")
dir.create(job_desc_folder)
# Define the base URL and save path
url <- "https://northcarolina.schoolspring.com"  # Target website
lea_name <- "schoolspring"
path <- paste(base_directory, lea_name, ".html", sep = "")
# Puppeteer JavaScript code to click jobs and save descriptions
js_code <- sprintf('
const puppeteer = require("puppeteer");
const fs = require("fs");
const path = require("path");
(async () => {
const browser = await puppeteer.launch({ headless: false }); // Set headless: false for debugging
const page = await browser.newPage();
const url = "%s"; // Target URL
const saveFolder = "%s"; // Folder to save job descriptions
const moreJobsButtonSelector = "#jobListPanel > div.div-more-jobs > button";
const jobSelector = "#joblist-div";  // Selector for job listings
const navigateAwayButtonSelector = "#navigate-away-from-section-dialog-btn-cancel"
// Step 1: Go to the target URL and click "More Jobs" button until it disappears
await page.goto(url, { waitUntil: "networkidle2" });
// Step 2: Click the "navigate-away" button to close the dialog (if it appears)
const navigateAwayButton = await page.$(navigateAwayButtonSelector);
if (navigateAwayButton) {
console.log("Clicking the navigate-away button...");
await navigateAwayButton.click();
await page.waitForTimeout(1000);  // Wait for the dialog to disappear
}
// Step 3: Click "More Jobs" button until it disappears
while (true) {
try {
// Wait for the "More Jobs" button to be available
const buttonExists = await page.waitForSelector(moreJobsButtonSelector, { timeout: 10000 });
if (buttonExists) {
console.log("Clicking More Jobs button...");
// Ensure the button is visible and interactable before clicking
await page.waitForFunction(
selector => {
const button = document.querySelector(selector);
return button && button.offsetParent !== null; // Check if the button is visible
},
{ timeout: 5000 },
moreJobsButtonSelector
);
await page.click(moreJobsButtonSelector);
await page.waitForTimeout(1000);  // Wait for new content to load
} else {
console.log("No more More Jobs button. All jobs loaded.");
break; // Exit loop when button disappears
}
} catch (error) {
console.error("Error clicking More Jobs button or button not found:", error);
break;
}
}
// Step 4: Fetch all job listing elements
let jobElements = await page.$$(jobSelector);
const totalJobs = jobElements.length; // Get the total number of jobs
console.log(`Found ${totalJobs} job listings.`);
// Step 5: Iterate through job listings
for (let i = 0; i < totalJobs; i++) {
try {
console.log(`Processing job listing ${i + 1} of ${totalJobs}...`); // Updated log
// Ensure fresh reference to the current element without re-fetching all elements
const jobElement = jobElements[i];
if (jobElement) {
await jobElement.click();
// Wait for job details to load completely (can include specific child elements)
await page.waitForSelector("#ApplicationDeadline-value", { timeout: 10000 }); // Wait for the job details container
// Fetch the HTML content inside #jobDetails-desktop
const jobContent = await page.evaluate(() => {
const jobDetails = document.querySelector("#jobDetails-desktop");
return jobDetails ? jobDetails.innerHTML : "";
});
// Define the file name
const fileName = path.join(saveFolder, `job_description_${i + 1}.html`);
// Write the content to an HTML file
fs.writeFileSync(fileName, jobContent);
console.log(`Saved full job content for job ${i + 1} of ${totalJobs} to ${fileName}`);
await page.waitForTimeout(300); // Slightly reduced wait
} else {
console.log(`Job element ${i + 1} of ${totalJobs} does not exist. Skipping.`);
}
} catch (error) {
console.error(`Error processing job ${i + 1} of ${totalJobs}:`, error);
}
}
console.log("Finished processing all job listings.");
await browser.close();
})();
', url, job_desc_folder)
# Specify the file path where you want to save the JavaScript code
js_file_path <- "/Users/wesleymorris/my-puppeteer-scraper/scraper_Puppeteer.js"
# Write the JavaScript code to the file
writeLines(js_code, con = js_file_path)
# Confirm that the file has been created
if (file.exists(js_file_path)) {
cat("JavaScript file successfully created at:", js_file_path, "\n")
} else {
stop("Failed to create JavaScript file.")
}
# Run the JavaScript code using Puppeteer
system(sprintf("cd /Users/wesleymorris/my-puppeteer-scraper && node %s", shQuote(js_file_path)))
# Set up the current date and directory structure
current_date <- format(Sys.Date(), "%Y%m%d")
new_folder_path <- file.path("/Users/wesleymorris/Desktop/EPP Geography/data/", current_date)
dir.create(new_folder_path, recursive = TRUE)  # Create parent directories if needed
base_directory <- paste(new_folder_path, "html/", sep = "/")
dir.create(base_directory)
# Create the Job_Descriptions folder
job_desc_folder <- file.path(new_folder_path, "Job_Descriptions")
dir.create(job_desc_folder)
# Define the base URL and save path
url <- "https://northcarolina.schoolspring.com"  # Target website
lea_name <- "schoolspring"
path <- paste(base_directory, lea_name, ".html", sep = "")
# Puppeteer JavaScript code to click jobs and save descriptions
js_code <- sprintf('
const puppeteer = require("puppeteer");
const fs = require("fs");
const path = require("path");
(async () => {
const browser = await puppeteer.launch({ headless: false }); // Set headless: false for debugging
const page = await browser.newPage();
const url = "%s"; // Target URL
const saveFolder = "%s"; // Folder to save job descriptions
const moreJobsButtonSelector = "#jobListPanel > div.div-more-jobs > button";
const jobSelector = "#joblist-div";  // Selector for job listings
const navigateAwayButtonSelector = "#navigate-away-from-section-dialog-btn-cancel"
// Step 1: Go to the target URL and click "More Jobs" button until it disappears
await page.goto(url, { waitUntil: "networkidle2" });
// Step 2: Click the "navigate-away" button to close the dialog (if it appears)
const navigateAwayButton = await page.$(navigateAwayButtonSelector);
if (navigateAwayButton) {
console.log("Clicking the navigate-away button...");
await navigateAwayButton.click();
await page.waitForTimeout(1000);  // Wait for the dialog to disappear
}
// Step 3: Click "More Jobs" button until it disappears
while (true) {
try {
// Wait for the "More Jobs" button to be available
const buttonExists = await page.waitForSelector(moreJobsButtonSelector, { timeout: 10000 });
if (buttonExists) {
console.log("Clicking More Jobs button...");
// Ensure the button is visible and interactable before clicking
await page.waitForFunction(
selector => {
const button = document.querySelector(selector);
return button && button.offsetParent !== null; // Check if the button is visible
},
{ timeout: 5000 },
moreJobsButtonSelector
);
await page.click(moreJobsButtonSelector);
await page.waitForTimeout(1000);  // Wait for new content to load
} else {
console.log("No more More Jobs button. All jobs loaded.");
break; // Exit loop when button disappears
}
} catch (error) {
console.error("Error clicking More Jobs button or button not found:", error);
break;
}
}
// Step 4: Fetch all job listing elements
let jobElements = await page.$$(jobSelector);
const totalJobs = jobElements.length; // Get the total number of jobs
console.log(`Found ${totalJobs} job listings.`);
// Step 5: Iterate through job listings
for (let i = 0; i < totalJobs; i++) {
try {
console.log(`Processing job listing ${i + 1} of ${totalJobs}...`); // Updated log
// Ensure fresh reference to the current element without re-fetching all elements
const jobElement = jobElements[i];
if (jobElement) {
await jobElement.click();
// Wait for job details to load completely (can include specific child elements)
await page.waitForSelector("#ApplicationDeadline-value", { timeout: 10000 }); // Wait for the job details container
// Fetch the HTML content inside #jobDetails-desktop
const jobContent = await page.evaluate(() => {
const jobDetails = document.querySelector("#jobDetails-desktop");
return jobDetails ? jobDetails.innerHTML : "";
});
// Define the file name
const fileName = path.join(saveFolder, `job_description_${i + 1}.html`);
// Write the content to an HTML file
fs.writeFileSync(fileName, jobContent);
console.log(`Saved full job content for job ${i + 1} of ${totalJobs} to ${fileName}`);
await page.waitForTimeout(300); // Slightly reduced wait
} else {
console.log(`Job element ${i + 1} of ${totalJobs} does not exist. Skipping.`);
}
} catch (error) {
console.error(`Error processing job ${i + 1} of ${totalJobs}:`, error);
}
}
console.log("Finished processing all job listings.");
await browser.close();
})();
', url, job_desc_folder)
# Specify the file path where you want to save the JavaScript code
js_file_path <- "/Users/wesleymorris/my-puppeteer-scraper/scraper_Puppeteer.js"
# Write the JavaScript code to the file
writeLines(js_code, con = js_file_path)
# Confirm that the file has been created
if (file.exists(js_file_path)) {
cat("JavaScript file successfully created at:", js_file_path, "\n")
} else {
stop("Failed to create JavaScript file.")
}
# Run the JavaScript code using Puppeteer
system(sprintf("cd /Users/wesleymorris/my-puppeteer-scraper && node %s", shQuote(js_file_path)))
# Load required libraries
library(rvest)
library(dplyr)
library(pbapply) # Progress bar for apply functions
# Function to extract job details from a single HTML file
extract_job_details <- function(file_path) {
# Read the HTML file
html <- read_html(file_path)
# Extract fields
job_title <- html %>% html_element(".job-details-job-title") %>% html_text(trim = TRUE)
job_id <- html %>% html_element("#jobId-value") %>% html_text(trim = TRUE)
employer_name <- html %>% html_element("#employerName-value") %>% html_text(trim = TRUE)
location <- html %>% html_element(".jobDetailsLocationName-value") %>% html_text(trim = TRUE)
position_type <- html %>% html_element("#PositionType-value") %>% html_text(trim = TRUE)
job_categories <- html %>% html_elements("[id^=jobCategories-value]") %>% html_text(trim = TRUE) %>% paste(collapse = "; ")
application_deadline <- html %>% html_element("#ApplicationDeadline-value") %>% html_text(trim = TRUE)
posted_date <- html %>% html_element("#DisplayDate-value") %>% html_text(trim = TRUE)
contact_name <- html %>% html_element("#contactInformation-value") %>% html_text(trim = TRUE)
contact_email <- html %>% html_element("#contactEmail-value a") %>% html_text(trim = TRUE)
# Return as a data frame
data.frame(
Job_Title = job_title,
Job_ID = job_id,
Employer_Name = employer_name,
Location = location,
Position_Type = position_type,
Job_Categories = job_categories,
Application_Deadline = application_deadline,
Posted_Date = posted_date,
Contact_Name = contact_name,
Contact_Email = contact_email,
File_Path = file_path,
stringsAsFactors = FALSE
)
}
# Set the input directory containing your job description HTML files
input_directory <- "/Users/wesleymorris/Desktop/EPP Geography/data/20250113/Job_Descriptions"
# Set the output directory to save the cleaned data
output_directory <- "/Users/wesleymorris/Desktop/data clean by date/update_v2"
# Create the output directory if it doesn't exist
if (!dir.exists(output_directory)) {
dir.create(output_directory, recursive = TRUE)
}
# Set the name of the final output file based on the scraping date
scraping_date <- "20250113"
output_file_path <- file.path(output_directory, paste0(scraping_date, ".csv"))
# List all HTML files in the input directory
job_files <- list.files(input_directory, pattern = "\\.html$", full.names = TRUE)
# Check if there are any files to process
if (length(job_files) == 0) {
stop("No HTML files found in the specified directory!")
}
# Loop through all files and extract job details with a progress bar
job_data_list <- pblapply(job_files, extract_job_details)
# Combine all job details into a single data frame
job_data <- bind_rows(job_data_list)
# Save the combined data to a CSV file
write.csv(job_data, file = output_file_path, row.names = FALSE)
# Print confirmation
cat("Data successfully saved to:", output_file_path, "\n")
# Set up the current date and directory structure
current_date <- format(Sys.Date(), "%Y%m%d")
new_folder_path <- file.path("/Users/wesleymorris/Desktop/EPP Geography/data/", current_date)
dir.create(new_folder_path, recursive = TRUE)  # Create parent directories if needed
base_directory <- paste(new_folder_path, "html/", sep = "/")
dir.create(base_directory)
# Create the Job_Descriptions folder
job_desc_folder <- file.path(new_folder_path, "Job_Descriptions")
dir.create(job_desc_folder)
# Define the base URL and save path
url <- "https://northcarolina.schoolspring.com"  # Target website
lea_name <- "schoolspring"
path <- paste(base_directory, lea_name, ".html", sep = "")
# Puppeteer JavaScript code to click jobs and save descriptions
js_code <- sprintf('
const puppeteer = require("puppeteer");
const fs = require("fs");
const path = require("path");
(async () => {
const browser = await puppeteer.launch({ headless: false }); // Set headless: false for debugging
const page = await browser.newPage();
const url = "%s"; // Target URL
const saveFolder = "%s"; // Folder to save job descriptions
const moreJobsButtonSelector = "#jobListPanel > div.div-more-jobs > button";
const jobSelector = "#joblist-div";  // Selector for job listings
const navigateAwayButtonSelector = "#navigate-away-from-section-dialog-btn-cancel"
// Step 1: Go to the target URL and click "More Jobs" button until it disappears
await page.goto(url, { waitUntil: "networkidle2" });
// Step 2: Click the "navigate-away" button to close the dialog (if it appears)
const navigateAwayButton = await page.$(navigateAwayButtonSelector);
if (navigateAwayButton) {
console.log("Clicking the navigate-away button...");
await navigateAwayButton.click();
await page.waitForTimeout(1000);  // Wait for the dialog to disappear
}
// Step 3: Click "More Jobs" button until it disappears
while (true) {
try {
// Wait for the "More Jobs" button to be available
const buttonExists = await page.waitForSelector(moreJobsButtonSelector, { timeout: 10000 });
if (buttonExists) {
console.log("Clicking More Jobs button...");
// Ensure the button is visible and interactable before clicking
await page.waitForFunction(
selector => {
const button = document.querySelector(selector);
return button && button.offsetParent !== null; // Check if the button is visible
},
{ timeout: 5000 },
moreJobsButtonSelector
);
await page.click(moreJobsButtonSelector);
await page.waitForTimeout(1000);  // Wait for new content to load
} else {
console.log("No more More Jobs button. All jobs loaded.");
break; // Exit loop when button disappears
}
} catch (error) {
console.error("Error clicking More Jobs button or button not found:", error);
break;
}
}
// Step 4: Fetch all job listing elements
let jobElements = await page.$$(jobSelector);
const totalJobs = jobElements.length; // Get the total number of jobs
console.log(`Found ${totalJobs} job listings.`);
// Step 5: Iterate through job listings
for (let i = 0; i < totalJobs; i++) {
try {
console.log(`Processing job listing ${i + 1} of ${totalJobs}...`); // Updated log
// Ensure fresh reference to the current element without re-fetching all elements
const jobElement = jobElements[i];
if (jobElement) {
await jobElement.click();
// Wait for job details to load completely (can include specific child elements)
await page.waitForSelector("#ApplicationDeadline-value", { timeout: 10000 }); // Wait for the job details container
// Fetch the HTML content inside #jobDetails-desktop
const jobContent = await page.evaluate(() => {
const jobDetails = document.querySelector("#jobDetails-desktop");
return jobDetails ? jobDetails.innerHTML : "";
});
// Define the file name
const fileName = path.join(saveFolder, `job_description_${i + 1}.html`);
// Write the content to an HTML file
fs.writeFileSync(fileName, jobContent);
console.log(`Saved full job content for job ${i + 1} of ${totalJobs} to ${fileName}`);
await page.waitForTimeout(300); // Slightly reduced wait
} else {
console.log(`Job element ${i + 1} of ${totalJobs} does not exist. Skipping.`);
}
} catch (error) {
console.error(`Error processing job ${i + 1} of ${totalJobs}:`, error);
}
}
console.log("Finished processing all job listings.");
await browser.close();
})();
', url, job_desc_folder)
# Specify the file path where you want to save the JavaScript code
js_file_path <- "/Users/wesleymorris/my-puppeteer-scraper/scraper_Puppeteer.js"
# Write the JavaScript code to the file
writeLines(js_code, con = js_file_path)
# Confirm that the file has been created
if (file.exists(js_file_path)) {
cat("JavaScript file successfully created at:", js_file_path, "\n")
} else {
stop("Failed to create JavaScript file.")
}
# Run the JavaScript code using Puppeteer
system(sprintf("cd /Users/wesleymorris/my-puppeteer-scraper && node %s", shQuote(js_file_path)))
# Load required libraries
library(rvest)
library(dplyr)
library(pbapply) # Progress bar for apply functions
# Function to extract job details from a single HTML file
extract_job_details <- function(file_path) {
# Read the HTML file
html <- read_html(file_path)
# Extract fields
job_title <- html %>% html_element(".job-details-job-title") %>% html_text(trim = TRUE)
job_id <- html %>% html_element("#jobId-value") %>% html_text(trim = TRUE)
employer_name <- html %>% html_element("#employerName-value") %>% html_text(trim = TRUE)
location <- html %>% html_element(".jobDetailsLocationName-value") %>% html_text(trim = TRUE)
position_type <- html %>% html_element("#PositionType-value") %>% html_text(trim = TRUE)
job_categories <- html %>% html_elements("[id^=jobCategories-value]") %>% html_text(trim = TRUE) %>% paste(collapse = "; ")
application_deadline <- html %>% html_element("#ApplicationDeadline-value") %>% html_text(trim = TRUE)
posted_date <- html %>% html_element("#DisplayDate-value") %>% html_text(trim = TRUE)
contact_name <- html %>% html_element("#contactInformation-value") %>% html_text(trim = TRUE)
contact_email <- html %>% html_element("#contactEmail-value a") %>% html_text(trim = TRUE)
# Return as a data frame
data.frame(
Job_Title = job_title,
Job_ID = job_id,
Employer_Name = employer_name,
Location = location,
Position_Type = position_type,
Job_Categories = job_categories,
Application_Deadline = application_deadline,
Posted_Date = posted_date,
Contact_Name = contact_name,
Contact_Email = contact_email,
File_Path = file_path,
stringsAsFactors = FALSE
)
}
# Set the input directory containing your job description HTML files
input_directory <- "/Users/wesleymorris/Desktop/EPP Geography/data/20250115/Job_Descriptions"
# Set the output directory to save the cleaned data
output_directory <- "/Users/wesleymorris/Desktop/data clean by date/update_v2"
# Create the output directory if it doesn't exist
if (!dir.exists(output_directory)) {
dir.create(output_directory, recursive = TRUE)
}
# Set the name of the final output file based on the scraping date
scraping_date <- "20250115"
output_file_path <- file.path(output_directory, paste0(scraping_date, ".csv"))
# List all HTML files in the input directory
job_files <- list.files(input_directory, pattern = "\\.html$", full.names = TRUE)
# Check if there are any files to process
if (length(job_files) == 0) {
stop("No HTML files found in the specified directory!")
}
# Loop through all files and extract job details with a progress bar
job_data_list <- pblapply(job_files, extract_job_details)
# Combine all job details into a single data frame
job_data <- bind_rows(job_data_list)
# Save the combined data to a CSV file
write.csv(job_data, file = output_file_path, row.names = FALSE)
# Print confirmation
cat("Data successfully saved to:", output_file_path, "\n")
install.packages(c("askpass", "backports", "BH", "bit", "bit64", "boot", "broom", "bslib", "cachem", "caret", "checkmate", "class", "classInt", "cli", "clock", "cluster", "colorspace", "commonmark", "cpp11", "crayon", "credentials", "curl", "data.table", "diffobj", "digest", "downlit", "e1071", "evaluate", "farver", "fastmap", "fastmatch", "fontawesome", "foreign", "fs", "future", "future.apply", "gert", "ggplot2", "globals", "glue", "gower", "gtable", "hardhat", "highr", "httpuv", "httr2", "ipred", "jsonlite", "KernSmooth", "knitr", "labelled", "later", "lattice", "lava", "lme4", "lubridate", "mathjaxr", "meta", "metadat", "metafor", "mgcv", "mime", "miniUI", "minqa", "mlr", "nlme", "nloptr", "NLP", "nnet", "openssl", "parallelly", "ParamHelpers", "pillar", "pkgbuild", "pkgdown", "pkgload", "processx", "prodlim", "profvis", "progressr", "promises", "ps", "purrr", "quarto", "questionr", "R.cache", "R.oo", "R.utils", "R6", "ragg", "randomForest", "Rcpp", "RcppEigen", "readxl", "recipes", "rlang", "rmarkdown", "roxygen2", "rpart", "rstudioapi", "sass", "scales", "sessioninfo", "shiny", "slam", "spatial", "stringi", "survival", "sys", "systemfonts", "testthat", "textshaping", "timeDate", "tinytex", "tm", "tzdb", "usethis", "utf8", "waldo", "withr", "xfun", "XML", "xml2", "yaml", "zip"))
king112
quarto render
quarto render
install.packages("quarto")
quarto render
setwd("~/Documents/GitHub/WesleyTMorris.github.io")
quarto render
quarto::quarto_render()
